# standard_config.yml

paths:
  dataset_path: ["../inputs/AtABFs_training_shuffle_neg_stride_200.csv", "../inputs/SiABFs_training_shuffle_neg_stride_200.csv"]
  dataset_split_path: "../inputs/data_splits/AtABFs-training_SiABFs-test_shuffle_neg_stride_200"
  model_dir: "../models/AtABFs-training_SiABFs-test/standard"
  test_result_dir: "../outputs/AtABFs-training_SiABFs-test/standard"
  
dataset_split:
  test_split_type: "cross"  # Options: 'random' or 'cross'
  val_split_type: "n-fold" # 'cross', 'n-fold': can be 'cross' when test_split_type is 'cross', as well
  id_column: "species"
  train_ids: [ "At" ] # should be assigned for 'cross' test_split_type
  val_ids: [] # should be assigned for 'cross' val_split_type
  test_ids: [ "Si" ] # should be assigned for 'cross' test_split_type
  test_size: 0.2 # should be assigned for 'random' test_split_type
  fold: 1 # should be > 1 for 'n-fold' val_split_type, else 1
  random_state: 436346

model:
  use_padding: true
  model_max_length: 350
  pretrained_model_name: "hyenadna-tiny-1k-seqlen"
      # 'hyenadna-tiny-1k-seqlen'
      # 'hyenadna-tiny-1k-seqlen-d256'
      # 'hyenadna-tiny-16k-seqlen-d128''
      # 'hyenadna-small-32k-seqlen'
      # 'hyenadna-medium-160k-seqlen'
      # 'hyenadna-medium-450k-seqlen'
      # 'hyenadna-large-1m-seqlen'
  is_finetuned: true
  use_saved_model: false
  saved_finetuned_model_name: "fine-tuned_model_batch_size_32_learning_rate_1e-4_weight_decay_0.1_freeze_layers-.pt"
  # "fine-tuned_model_batch_size_32_learning_rate_1e-4_weight_decay_0.1_freeze_layers-.pt"

device: "cuda"
  
training:
  num_epochs: 60
  model_params:
    batch_size: [32]
#    learning_rate: [1e-4]
    weight_decay: [0.1]
#    batch_size: [ 32, 64, 128, 256 ]
    learning_rate: [ 1e-3 ]
#    weight_decay: [ 0.0, 0.01, 0.1 ]
  early_stopping:
    patience: 5
    delta: 0.0
  freeze_layers: [['backbone'], ['backbone.embeddings'], ['backbone.layers'], ['none']]
  # 'backbone.embeddings': Freezes the embedding layer.
  # 'backbone.layers'    : Freezes all transformer blocks.
  # 'backbone.layers.[i]': Freezes a specific transformer block.
  # 'backbone'           : Freezes the entire backbone (embeddings + all transformer layers).
  # 'head'               : Freezes the output classification head.

wandb:
  enabled: True
  token: 'dc3d431c0afb735d9ac046c72f076bf1f7656472'
  project_name: 'HyenaDNA-CrossSpecies'
  entity_name: 'haghani-vt'
  timezone: 'US/Eastern'
  timezone_format: '%Y-%m-%d_%H-%M-%S'