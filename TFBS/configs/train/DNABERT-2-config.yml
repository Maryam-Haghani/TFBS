output_dir: "../outputs"

model:
  model_name: "DNABERT-2"
  max_length: 264
  finetune_type: "standard" # options: LoRA, standard

device: "cuda"

training:
  num_epochs: 15
  adjustable_LR:
    enabled: true
    max: 2e-6
    min: 1.5e-5
  model_params:
    freeze_layers: ['none']
    train_batch_size: [32]
    learning_rate: [1.5e-5]
    weight_decay: [1e-2]
  early_stopping:
    patience: 10
    delta: 0.0

wandb:
  enabled: True
  token: 'dc3d431c0afb735d9ac046c72f076bf1f7656472'
  entity_name: 'haghani-vt'
  timezone: 'US/Eastern'
  timezone_format: '%Y-%m-%d_%H-%M-%S'